{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e76f02",
   "metadata": {},
   "source": [
    "## 1. Ingestion (Bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from mysql.connector import errorcode\n",
    "from tools.database import DatabaseManager\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0496019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "# --- CONFIGURATION SYSTÃˆME (Obligatoire pour Windows) ---\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# DÃ©sactivation temporaire du recyclage des workers (Ã©vite les erreurs de sockets sur Windows)\n",
    "os.environ['PYSPARK_PYTHON_WORKER_REUSE'] = \"0\"\n",
    "\n",
    "# --- PRÃ‰PARATION MYSQL ---\n",
    "db_tools = DatabaseManager(user=\"root\", password=\"root\")\n",
    "db_tools.setup_database(\"openfood_db\")\n",
    "jdbc_url, connection_props = db_tools.get_jdbc_params(\"openfood_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INITIALISATION SPARK ---\n",
    "# --- CHEMINS ---\n",
    "jdbc_jar = r\".\\driver\\mysql-connector-j-8.0.33\\mysql-connector-j-8.0.33.jar\"\n",
    "\n",
    "# --- INITIALISATION SESSION ---\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"OpenFoodFacts_ETL\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.python.worker.timeout\", \"120\") \\\n",
    "    .config(\"spark.jars\", jdbc_jar) \\\n",
    "    .config(\"spark.driver.extraClassPath\", jdbc_jar) \\\n",
    "    .config(\"spark.executor.extraClassPath\", jdbc_jar) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Session Spark crÃ©Ã©e avec succÃ¨s !\")\n",
    "\n",
    "# --- TEST DE DIAGNOSTIC ---\n",
    "try:\n",
    "    print(\"Test de communication Python-Java...\")\n",
    "    spark.createDataFrame([(1, \"test\")], [\"id\", \"val\"]).collect()\n",
    "    print(\"âœ… Communication OK !\")\n",
    "except Exception as e:\n",
    "    print(\"âŒ Ã‰chec de communication interne :\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130992aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"./data/openfoodfacts.csv\"\n",
    "\n",
    "bronze_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"mode\", \"PERMISSIVE\") \\\n",
    "    .csv(csv_path)\n",
    "\n",
    "bronze_df.printSchema()\n",
    "print(bronze_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed37a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Nombre de lignes ===\")\n",
    "print(bronze_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae787d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Nombre de colonnes ===\")\n",
    "print(len(bronze_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SchÃ©ma infÃ©rÃ© ===\")\n",
    "bronze_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d240e6",
   "metadata": {},
   "source": [
    "## 2. Nettoyage & qualitÃ© (Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. LISTING DES COLONNES NECESSAIRE ---\n",
    "cols_needed = [\n",
    "    \"code\", \"product_name\", \"brands\", \"main_category\",\"categories_en\", \"countries_en\",\n",
    "    \"last_modified_t\", \"nutriscore_grade\", \n",
    "    \"energy-kcal_100g\", \"fat_100g\", \"saturated-fat_100g\", \"sugars_100g\", \n",
    "    \"salt_100g\", \"proteins_100g\", \"fiber_100g\", \"sodium_100g\", \"completeness\"\n",
    "]\n",
    "\n",
    "# On filtre les colonnes pour ne prendre que celles qui existent rÃ©ellement dans le fichier source\n",
    "existing_cols = [c for c in cols_needed if c in bronze_df.columns]\n",
    "silver_df = bronze_df.select(*existing_cols)\n",
    "\n",
    "# --- 2. RENOMMAGE (Suppression des tirets pour MySQL) ---\n",
    "for c in silver_df.columns:\n",
    "    if \"-\" in c:\n",
    "        silver_df = silver_df.withColumnRenamed(c, c.replace(\"-\", \"_\"))\n",
    "\n",
    "# --- VERIFICATION ---\n",
    "print(f\"=== Nombre de colonnes : {len(silver_df.columns)} ===\")\n",
    "print(f\"=== Nombre de lignes : {silver_df.count()} ===\")\n",
    "print(silver_df.columns)\n",
    "silver_df.select(\"main_category\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9369a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace, lower, trim, udf\n",
    "import unicodedata\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Liste des colonnes Ã  ne PAS toucher\n",
    "cols_to_exclude = [\"countries_en\", \"main_category\", \"categories_en\"]\n",
    "\n",
    "# 1. PrÃ©paration de l'UDF pour la normalisation ASCII\n",
    "clean_ascii_udf = udf(\n",
    "    lambda text: \n",
    "        unicodedata.normalize('NFD', unicodedata.normalize('NFKC', text))\n",
    "        .encode('ascii', 'ignore')\n",
    "        .decode('utf-8') if text is not None else None, \n",
    "    StringType()\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Identification des colonnes texte dans silver_df\n",
    "string_cols = [c for c, t in silver_df.dtypes if t == \"string\" and c not in cols_to_exclude]\n",
    "\n",
    "# 3. Application du bloc de nettoyage complet\n",
    "for col_name in string_cols:\n",
    "    silver_df = silver_df.withColumn(col_name, \n",
    "        # Suppression des espaces multiples et mise en forme finale\n",
    "        regexp_replace(\n",
    "            lower(\n",
    "                trim(\n",
    "                    # Filtre alphanumÃ©rique (garde lettres, chiffres et espaces)\n",
    "                    regexp_replace(\n",
    "                        # Normalisation ASCII (via l'UDF)\n",
    "                        clean_ascii_udf(col(col_name)), \n",
    "                        \"[^a-zA-Z0-9 ]\", \"\"\n",
    "                    )\n",
    "                )\n",
    "            ), \n",
    "            \"\\\\s+\", \" \"\n",
    "        )\n",
    "    )\n",
    "\n",
    "silver_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de256bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_df = silver_df.withColumn(\"main_category\", \n",
    "    regexp_replace(\n",
    "        split(col(\"main_category\"), \"-\").getItem(0), \n",
    "        \"^[a-z]{2}:\", \"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "cols = [\"countries_en\", \"main_category\", \"categories_en\"]\n",
    "\n",
    "for col_name in cols:\n",
    "    silver_df = silver_df.withColumn(col_name,\n",
    "        clean_ascii_udf(lower(trim(col(col_name)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7096bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAITEMENT DES COLONNES ---\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "text_columns = [\n",
    "    (\"categories_en\", \"categories\", \"non classe\"),\n",
    "    (\"main_category\", None, \"non classe\"),\n",
    "    (\"brands\", None, \"marque inconnue\"),\n",
    "    (\"countries_en\", None, \"pays inconue\"),\n",
    "    (\"nutriscore_grade\", None, \"non classe\"),\n",
    "]\n",
    "\n",
    "invalid_vals = [\"undefined\", \"null\", \"unknown\", \"none\", \"n/a\", \"\"]\n",
    "\n",
    "# --- TRAITEMENT ---\n",
    "for main_col, fallback_col, default_val in text_columns:\n",
    "    if main_col in silver_df.columns:\n",
    "        \n",
    "        # 1. DÃ©finition de la condition de validitÃ© (rÃ©utilisable)\n",
    "        def get_valid_col(c):\n",
    "            return when((col(c).isNotNull()) & (~lower(col(c)).isin(invalid_vals)), col(c))\n",
    "\n",
    "        # 2. Logique de remplacement (Coalesce gÃ¨re la prioritÃ© : Main > Fallback > Default)\n",
    "        if fallback_col and fallback_col in silver_df.columns:\n",
    "            silver_df = silver_df.withColumn(\n",
    "                main_col,\n",
    "                coalesce(get_valid_col(main_col), get_valid_col(fallback_col), lit(default_val))\n",
    "            ).drop(fallback_col)\n",
    "        else:\n",
    "            silver_df = silver_df.withColumn(\n",
    "                main_col,\n",
    "                coalesce(get_valid_col(main_col), lit(default_val))\n",
    "            )\n",
    "\n",
    "        # 3. Troncature Ã  255 caractÃ¨res\n",
    "        silver_df = silver_df.withColumn(main_col, substring(col(main_col), 1, 255))\n",
    "\n",
    "silver_df = silver_df.withColumn(\n",
    "    \"countries_en\",\n",
    "    split(col(\"countries_en\"), \",\\s*\")\n",
    ")\n",
    "\n",
    "# Spark va transformer [a, b] en \"[a, b]\" (format texte)\n",
    "silver_df = silver_df.withColumn(\n",
    "    \"countries_en\", \n",
    "    F.col(\"countries_en\").cast(\"string\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a9078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. DÃ‰DUPLICATION FINALE ---\n",
    "if \"code\" in silver_df.columns:\n",
    "    # On trie par date de modification dÃ©croissante (la plus rÃ©cente en premier)\n",
    "    # Puis on supprime les doublons basÃ©s sur le code-barres\n",
    "    silver_df = silver_df.orderBy(col(\"last_modified_t\").desc()) \\\n",
    "                         .dropDuplicates([\"code\"])\n",
    "\n",
    "print(\"âœ… Nettoyage terminÃ© : catÃ©gories simplifiÃ©es et donnÃ©es normalisÃ©es.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e20dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On dÃ©finit des seuils biologiques/physiques pour chaque nutriment.\n",
    "# Si une valeur dÃ©passe ces bornes (ex: > 100g de sucre pour 100g de produit), \n",
    "# on la remplace par NULL pour ne pas fausser les moyennes statistiques plus tard.\n",
    "\n",
    "# 1. Filtrage par seuils\n",
    "nutrient_bounds = {\n",
    "    \"energy_kcal_100g\": (0, 1000),\n",
    "    \"fat_100g\": (0, 100),\n",
    "    \"saturated_fat_100g\": (0, 100),\n",
    "    \"sugars_100g\": (0, 100),\n",
    "    \"salt_100g\": (0, 100),\n",
    "    \"proteins_100g\": (0, 100),\n",
    "    \"fiber_100g\": (0, 100),\n",
    "    \"sodium_100g\": (0, 40),\n",
    "    \"completeness\": (0, 1)\n",
    "}\n",
    "\n",
    "for col_name, (min_val, max_val) in nutrient_bounds.items():\n",
    "    if col_name in silver_df.columns:\n",
    "         silver_df = silver_df.withColumn(\n",
    "            col_name,\n",
    "            when((col(col_name) >= min_val) & (col(col_name) <= max_val), col(col_name))\n",
    "            .otherwise(None)\n",
    "         )\n",
    "\n",
    "# 2. Calcul des colonnes d'estimation\n",
    "if \"sodium_100g\" in silver_df.columns:\n",
    "    silver_df = silver_df.withColumn(\"salt_est\", col(\"sodium_100g\") * 2.5)\n",
    "\n",
    "if \"salt_100g\" in silver_df.columns:\n",
    "    silver_df = silver_df.withColumn(\"sodium_est\", col(\"salt_100g\") / 2.5)\n",
    "\n",
    "# 3. Remplissage des donnÃ©es manquantes\n",
    "if \"salt_100g\" in silver_df.columns and \"salt_est\" in silver_df.columns:\n",
    "    silver_df = silver_df.withColumn(\"salt_100g\", coalesce(col(\"salt_100g\"), col(\"salt_est\")))\n",
    "\n",
    "if \"sodium_100g\" in silver_df.columns and \"sodium_est\" in silver_df.columns:\n",
    "    silver_df = silver_df.withColumn(\"sodium_100g\", coalesce(col(\"sodium_100g\"), col(\"sodium_est\")))\n",
    "\n",
    "# 4. Conversion kcal â†’ kJ\n",
    "if \"energy_kcal_100g\" in silver_df.columns:\n",
    "    silver_df = silver_df.withColumn(\"energy_kj_100g\", col(\"energy_kcal_100g\") * 4.184)\n",
    "\n",
    "# 5. Formatage final (Arrondi)\n",
    "# On ajoute energy_kj_100g Ã  la liste des colonnes Ã  arrondir\n",
    "cols_to_round = list(nutrient_bounds.keys()) + [\"energy_kj_100g\"]\n",
    "for col_name in cols_to_round: \n",
    "    if col_name in silver_df.columns: \n",
    "        silver_df = silver_df.withColumn(col_name, round(col(col_name), 1))\n",
    "\n",
    "# 6. Nettoyage\n",
    "silver_df = silver_df.drop(\"salt_est\", \"sodium_est\")\n",
    "\n",
    "silver_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion du unix en timestamp et on garde uniquement que la date\n",
    "\n",
    "if \"last_modified_t\" in silver_df.columns:\n",
    "    silver_df = silver_df.withColumn(\n",
    "        \"last_modified_ts\",\n",
    "        to_timestamp(col(\"last_modified_t\").cast(\"double\"))\n",
    "    ).withColumn(\n",
    "        \"last_modified_date\",\n",
    "        to_date(col(\"last_modified_ts\"))\n",
    "    )\n",
    "\n",
    "silver_df.select(\"last_modified_date\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. On supprime les doublons\n",
    "w = Window.partitionBy(\"code\").orderBy(col(\"last_modified_t\").cast(\"long\").desc())\n",
    "\n",
    "silver_dedup = silver_df.withColumn(\"rn\", row_number().over(w)) \\\n",
    "    .filter(col(\"rn\") == 1) \\\n",
    "    .drop(\"rn\")\n",
    "\n",
    "# 2. On enlÃ¨ve les NULL et les chaÃ®nes de caractÃ¨res vides\n",
    "silver_final = silver_dedup.filter(\n",
    "    (col(\"code\").isNotNull()) & \n",
    "    (col(\"code\") != \"\") & \n",
    "    (col(\"code\") != \"null\")\n",
    ")\n",
    "\n",
    "# 3. Petit rapport de qualitÃ©\n",
    "print(f\"Lignes avant nettoyage : {silver_dedup.count()}\")\n",
    "print(f\"Lignes aprÃ¨s nettoyage (code valide) : {silver_final.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efa00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation (la connexion self.conn se crÃ©e ici)\n",
    "db_tools = DatabaseManager(user=\"root\", password=\"root\")\n",
    "\n",
    "# 2. ParamÃ¨tres pour Spark\n",
    "jdbc_url, connection_props = db_tools.get_jdbc_params(\"openfood_db\")\n",
    "\n",
    "# 3. Ã‰criture (via Spark JDBC)\n",
    "try:\n",
    "    # On force le mode \"overwrite\" pour Ã©craser la table si elle existe dÃ©jÃ \n",
    "    silver_final.write.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=\"silver_products\",\n",
    "        mode=\"overwrite\", \n",
    "        properties=connection_props\n",
    "    )\n",
    "    print(\"âœ… Transfert Spark vers MySQL rÃ©ussi !\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur Spark JDBC : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68e238",
   "metadata": {},
   "source": [
    "## 3. Dimensions (Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3972b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DIM_TIME ---\n",
    "df_dim_time = silver_final.select(\"last_modified_t\").distinct() \\\n",
    "    .withColumn(\"ts_date\", from_unixtime(col(\"last_modified_t\")).cast(\"date\")) \\\n",
    "    .select(\n",
    "        col(\"last_modified_t\").alias(\"time_sk\"),\n",
    "        col(\"ts_date\").alias(\"date\"),\n",
    "        year(\"ts_date\").alias(\"year\"),\n",
    "        month(\"ts_date\").alias(\"month\"),\n",
    "        dayofmonth(\"ts_date\").alias(\"day\"),\n",
    "        weekofyear(\"ts_date\").alias(\"week\"),\n",
    "        weekofyear(\"ts_date\").alias(\"iso_week\")\n",
    "    )\n",
    "\n",
    "# --- DIM_BRAND ---\n",
    "df_dim_brand = silver_final.select(col(\"brands\").alias(\"brand_name\")) \\\n",
    "    .filter(col(\"brand_name\").isNotNull() & (col(\"brand_name\") != \"\")) \\\n",
    "    .distinct() \\\n",
    "    .withColumn(\"brand_name\", substring(col(\"brand_name\"), 1, 500))\n",
    "\n",
    "# --- DIM_CATEGORY ---\n",
    "df_dim_category = silver_final.select(\n",
    "    substring(lower(trim(col(\"categories_en\"))), 1, 500).alias(\"category_name\"),\n",
    "    substring(lower(trim(col(\"main_category\"))), 1, 500).alias(\"parent_category_sk\")\n",
    ") \\\n",
    ".filter(col(\"category_name\").isNotNull() & (col(\"category_name\") != \"\")) \\\n",
    ".dropDuplicates([\"category_name\"]) # <--- UnicitÃ© garantie pour MySQL\n",
    "\n",
    "# --- DIM_COUNTRY ---\n",
    "df_dim_country = silver_final.select(\n",
    "    col(\"countries_en\").alias(\"countries_name\")) \\\n",
    ".filter(col(\"countries_name\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuration JDBC\n",
    "jdbc_url, connection_props = db_tools.get_jdbc_params(\"openfood_db\")\n",
    "\n",
    "try:\n",
    "    # --- NETTOYAGE ---\n",
    "    print(\"ðŸ§¹ Truncate des tables Gold...\")\n",
    "    # On utilise une connexion directe pour le truncate\n",
    "    conn = db_tools._get_connection(\"openfood_db\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0;\")\n",
    "    tables = [\"dim_time\", \"dim_brand\", \"dim_category\", \"dim_country\"]\n",
    "    for t in tables: cursor.execute(f\"TRUNCATE TABLE {t};\")\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 1;\")\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    \n",
    "    # --- ETAPE 1 : Dimensions IndÃ©pendantes ---\n",
    "    print(\"ðŸš€ Insertion des dimensions de base (Time, Brand, Category, Country)...\")\n",
    "    df_dim_time.write.jdbc(url=jdbc_url, table=\"dim_time\", mode=\"append\", properties=connection_props)\n",
    "    df_dim_brand.write.jdbc(url=jdbc_url, table=\"dim_brand\", mode=\"append\", properties=connection_props)\n",
    "    df_dim_category.write.jdbc(url=jdbc_url, table=\"dim_category\", mode=\"append\", properties=connection_props)\n",
    "    df_dim_country.write.jdbc(url=jdbc_url, table=\"dim_country\", mode=\"append\", properties=connection_props)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur critique lors de l'alimentation Gold : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url, connection_props = db_tools.get_jdbc_params(\"openfood_db\")\n",
    "df_mysql_brand = spark.read.jdbc(url=jdbc_url, table=\"dim_brand\", properties=connection_props) \n",
    "df_mysql_category = spark.read.jdbc(url=jdbc_url, table=\"dim_category\", properties=connection_props) \n",
    "\n",
    "# --- 2. Construction de DIM_PRODUCT ---\n",
    "df_dim_product = silver_final.select(\n",
    "    \"code\", \n",
    "    \"product_name\", \n",
    "    \"brands\", \n",
    "    \"main_category\", \n",
    "    col(\"countries_en\").alias(\"countries_multi_name\") # Retrait du 's' ici\n",
    ")\n",
    "\n",
    "# On rÃ©cupÃ¨re les SK des marques\n",
    "df_dim_product = df_dim_product.join(\n",
    "    df_mysql_brand.select(\"brand_sk\", \"brand_name\"),\n",
    "    df_dim_product.brands == df_mysql_brand.brand_name,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# On rÃ©cupÃ¨re les SK des catÃ©gories\n",
    "df_dim_product = df_dim_product.join(\n",
    "    df_mysql_category.select(\"category_sk\", \"category_name\"),\n",
    "    df_dim_product.main_category == df_mysql_category.category_name,\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "# SÃ©lection finale\n",
    "df_dim_product_final = df_dim_product.select(\n",
    "    col(\"code\"),\n",
    "    col(\"product_name\"),\n",
    "    col(\"brand_sk\"),\n",
    "    col(\"category_sk\").alias(\"primary_category_sk\"),\n",
    "    col(\"countries_multi_name\") # Plus besoin d'alias ici, le nom est dÃ©jÃ  bon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196fd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url, connection_props = db_tools.get_jdbc_params(\"openfood_db\")\n",
    "\n",
    "try:\n",
    "    # --- NETTOYAGE ---\n",
    "    print(\"ðŸ§¹ Truncate des tables Gold...\")\n",
    "    # On utilise une connexion directe pour le truncate\n",
    "    conn = db_tools._get_connection(\"openfood_db\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0;\")\n",
    "    tables = [\"dim_product\"]\n",
    "    for t in tables: cursor.execute(f\"TRUNCATE TABLE {t};\")\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 1;\")\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    \n",
    "    # --- ETAPE 1 : Dimensions IndÃ©pendantes ---\n",
    "    print(\"ðŸš€ Insertion de la dimension de Product\")\n",
    "    df_dim_product_final.write.jdbc(url=jdbc_url, table=\"dim_product\", mode=\"append\", properties=connection_props)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur critique lors de l'alimentation Gold : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On recharge la table dim_product depuis MySQL pour avoir les product_sk\n",
    "df_mysql_product = spark.read.jdbc(url=jdbc_url, table=\"dim_product\", properties=connection_props) \n",
    "\n",
    "# --- 3. Construction de FACT_NUTRITION_SNAPSHOT ---\n",
    "df_fact = silver_final.select(\n",
    "    \"code\", \"last_modified_t\", \"energy_kcal_100g\", \"fat_100g\", \"saturated_fat_100g\",\n",
    "    \"sugars_100g\", \"salt_100g\", \"proteins_100g\", \"fiber_100g\", \"sodium_100g\",\n",
    "    \"nutriscore_grade\", \"completeness\"\n",
    ")\n",
    "\n",
    "df_fact_final = df_fact.join(\n",
    "    df_mysql_product.select(\"product_sk\", \"code\"),\n",
    "    \"code\",\n",
    "    \"inner\"\n",
    ").select(\n",
    "    col(\"product_sk\"),\n",
    "    col(\"last_modified_t\").alias(\"time_sk\"),\n",
    "    \"energy_kcal_100g\", \"fat_100g\", \"saturated_fat_100g\", \"sugars_100g\", \n",
    "    \"salt_100g\", \"proteins_100g\", \"fiber_100g\", \"sodium_100g\", \n",
    "    \"nutriscore_grade\", \n",
    "    col(\"completeness\").alias(\"completeness_score\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url, connection_props = db_tools.get_jdbc_params(\"openfood_db\")\n",
    "\n",
    "try:\n",
    "    # --- NETTOYAGE ---\n",
    "    print(\"ðŸ§¹ Truncate des tables Gold...\")\n",
    "    # On utilise une connexion directe pour le truncate\n",
    "    conn = db_tools._get_connection(\"openfood_db\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0;\")\n",
    "    tables = [\"fact_nutrition_snapshot\"]\n",
    "    for t in tables: cursor.execute(f\"TRUNCATE TABLE {t};\")\n",
    "    cursor.execute(\"SET FOREIGN_KEY_CHECKS = 1;\")\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    \n",
    "    # --- ETAPE 1 : Dimensions IndÃ©pendantes ---\n",
    "    print(\"ðŸš€ Insertion de la table de fait\")\n",
    "    df_fact_final.write.jdbc(url=jdbc_url, table=\"fact_nutrition_snapshot\", mode=\"append\", properties=connection_props)\n",
    "\n",
    "    print(\"âœ¨ ARCHITECTURE GOLD TERMINEE AVEC SUCCÃˆS !\")\n",
    "\n",
    "    end_time = datetime.now()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur critique lors de l'alimentation Gold : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8256ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"source\": \"OpenFoodFacts CSV\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"duree_minutes\": (end_time - start_time).seconds / 60,\n",
    "    \"nombre_lignes_initial\": bronze_df.count(),\n",
    "    \"nombre_lignes_traitees\": silver_final.count(),\n",
    "    \"nombre_lignes_rejetees\": bronze_df.count() - silver_final.count(),\n",
    "    \"taux_completude_moyen\": df_fact.agg({\"completeness\": \"avg\"}).first()[0],\n",
    "    \"pct_nutriscore\": silver_final.filter(col(\"nutriscore_grade\").isNotNull()).count() / silver_final.count(),\n",
    "    \"nb_sugars_anomalies\": silver_final.filter(col(\"sugars_100g\") > 100).count(),\n",
    "    \"status\": \"SUCCESS\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "output_dir = \"./metrics\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# file name with timestamp\n",
    "run_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = f\"{output_dir}/metrics_{run_ts}.json\"\n",
    "\n",
    "# write JSON\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Metrics saved in : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ccc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
